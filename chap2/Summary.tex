%o   Introduce problem area / give relevant background info
%\\o   Introduction - Explain WHY you are doing this study
%\\o   Information - Background / your study in the wider context
%\\o   Similar work (projects, systems etc.)
%\\o   Summary - for this chapter
Google Glass was announced in 2012 along with the statement ``We think technology should work for you---to be there when you need it and get out of your way when you don't.''~\cite{GoogleGlassAnnouncement}. Google wanted to create a device where the user did not have to look down~\cite{tedtalkWhyGlass} as well as a device where the time between intention and action was minimised~\cite{6504855}. 

Google Glass (see Figure~\ref{GoogleGlassHardware}~(a) and~(b)) is an small HMD that is partially controlled with a touchpad mounted on the right hand side of the frames. The display sits slightly above the user's line of sight, on the right hand side. Google Glass' display is a projection that goes through an optic lense, creating a virtual image which makes the perception of the display to be equivalent of a 25 inch high definition screen seen from a distance of approximately 2.5 meters~\cite{GlassSpecs}.

Today there are many products similar to Google Glass either already on the market or in development. Microsoft Hololens is an HMD focused on letting the user work in a 3D space (with for instance 3D modelling~\cite{hololensDemo}) by covering both of the user's eyes. Recon Jet, GlassUp and C Wear Interactive Glasses are three products more similar to Google Glass in the sense that they only display information in front of one eye. However, Recon Jet is aimed at athletes, to be used while athletes are working out. GlassUp and C Wear Interactive Glasses are meant to be connected to an external device, such as a smartphone or a PC. Google Glass is a stand-alone device meant to be worn at all times.

The GUI of Google Glass is called a timeline and consists of a row of cards~\cite{ImagesGoogleGlassUI}. Cards are basic activities, such as a clock, but may also represent more in-depth applications, such as a game, on Google Glass called ``Immersions''. The center point of the timeline is the home screen and the first screen the user sees when turning on Google Glass. Cards to the left of the home screen are upcoming events, such as a flight, and cards to the right of the home screen are from the past, such as text messages. The user moves left on the timeline by swiping a finger backwards on the touchpad and in order to move right the user must swipe a finger forwards on the touchpad. 

In order to play sounds Google Glass uses a BCT which transfers sound through the bones of the skull~\cite{GlassSpecs}. The advantage of this technique is that external sound is not blocked out. In order to capture the environment Google Glass is also equipped with a 5 megapixles camera~\cite{GlassSpecs} and a microphone. Using the camera and the microphone the user may give input to Google Glass, for instance when using voice commands in order to control Google Glass hands-free.

The hands-free experience is also what sets Google Glass appart from regular smartphones. Smartphones must be held by the user or put on a table. The user must also look down at the screen of a smartphone, in contrast to Google Glass which puts the display slightly above the user's line of sight. Smartphones does however give the user a bit more control with multi-touch and touchscreen. Another advantage of smartphones is the larger screens. Smartphone screens have been increasing in size ever since the iPhone launched in 2007~\cite{smartphoneSizeChart2}. However, as HMDs increase in popularity, there is potential for a wider offering of models and screen sizes.

Smartphones and Google Glass may in many cases be used for similar applications. For instance QR code scanning, since both smartphones and Google Glass are equipped with a camera. The QR code was announced in 1994 by Denso Wave~\cite{qrCodeHistory}. The goal was to create a new form af barcode that could carry more information than a linear barcode and be easily read. While a conventional bardoce is capable of storing approximately 10 digits a QR code can store several thousand digits~\cite{qrCodeType}. A QR code also uses position fields which make the QR code readable from any direction, compared to a conventional barcode which can only be read horizontally~\cite{qrCodeAbout}. A QR code can be used to encode information, originally written with alphabetic characters, japanese symbols (Kanji) or numeric characters~\cite{qrCodeVersion}. 

Information has been defined as ``a large number of examples from texts of different kinds''~\cite{informationDef1} and may be presented in a number of different ways. The four main ways of presenting information are text, images, sound and video. Text and images both have the advantage of being independent of time. Readers/viewers may perceive the information at their own pace. Images may also be divided into photographs and graphs. The difference of the two lies in the fact that graphs are used to present statistical information. Text and images does however both share the disadvantage of requiring readers/viewers vision.

Audio solves the problem of requiring the user's vision since audio uses a different sense. The listener may as a result multitask in terms of listening to the information being presented through audio while performing other tasks. For instance the listener may be listening to the radio while driving a car. In contrast to text and images audio is not independent of time. Video has the same disadvantage as audio of not being independent of time. Video is, however, unique as video is the only form of presenting information which may combine images and as such show movement. Adding audio to video gives viewers the advantage of choice as they may choose to either watch or only listen.